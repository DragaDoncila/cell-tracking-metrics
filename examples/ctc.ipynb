{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Cell Tracking Challenge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from traccuracy import run_metrics\n",
    "from traccuracy.loaders import load_ctc_data\n",
    "from traccuracy.matchers import CTCMatcher, IOUMatcher\n",
    "from traccuracy.metrics import CTCMetrics, DivisionMetrics\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://data.celltrackingchallenge.net/training-datasets/Fluo-N2DL-HeLa.zip\"\n",
    "data_dir = 'downloads'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "filename = url.split('/')[-1]\n",
    "file_path = os.path.join(data_dir, filename)\n",
    "ds_name = filename.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Fluo-N2DL-HeLa data from the CTC website\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fluo-N2DL-HeLa.zip: 199MB [00:18, 10.6MB/s]                              \n"
     ]
    }
   ],
   "source": [
    "# Add a utility to make a progress bar when downloading the file\n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Downloading {ds_name} data from the CTC website\")\n",
    "    # Downloading data\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, file_path, reporthook=t.update_to)\n",
    "    # Unzip the data\n",
    "    # TODO add a progress bar to zip as well\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TIFFs: 100%|██████████| 92/92 [00:00<00:00, 419.73it/s]\n",
      "Computing node attributes: 100%|██████████| 92/92 [00:00<00:00, 304.98it/s]\n",
      "1 non-connected masks at t=23.\n",
      "2 non-connected masks at t=52.\n",
      "Loading TIFFs: 100%|██████████| 92/92 [00:00<00:00, 553.93it/s]\n",
      "Computing node attributes: 100%|██████████| 92/92 [00:00<00:00, 274.08it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gt_data = load_ctc_data(\n",
    "    'downloads/Fluo-N2DL-HeLa/01_GT/TRA',\n",
    "    'downloads/Fluo-N2DL-HeLa/01_GT/TRA/man_track.txt',\n",
    "    name='Hela-01_GT'\n",
    ")\n",
    "pred_data = load_ctc_data(\n",
    "    'sample-data/Fluo-N2DL-HeLa/01_RES',\n",
    "    'sample-data/Fluo-N2DL-HeLa/01_RES/res_track.txt',\n",
    "    name='Hela-01_RES'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run CTC metrics with additional evaluation of division events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching frames: 100%|██████████| 92/92 [00:00<00:00, 188.47it/s]\n",
      "Evaluating nodes: 100%|██████████| 8600/8600 [00:00<00:00, 617062.65it/s]\n",
      "Evaluating FP edges: 100%|██████████| 8535/8535 [00:00<00:00, 1076546.02it/s]\n",
      "Evaluating FN edges: 100%|██████████| 8562/8562 [00:00<00:00, 1080373.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'gt': 'Hela-01_GT',\n",
      "        'matcher': {'name': 'CTCMatcher'},\n",
      "        'metric': {   'e_weights': {'fn': 1.5, 'fp': 1, 'ws': 1},\n",
      "                      'name': 'CTCMetrics',\n",
      "                      'v_weights': {'fn': 10, 'fp': 1, 'ns': 5}},\n",
      "        'pred': 'Hela-01_RES',\n",
      "        'results': {   'AOGM': 627.5,\n",
      "                       'DET': 0.9954855886097927,\n",
      "                       'TRA': 0.993676498745377,\n",
      "                       'fn_edges': 87,\n",
      "                       'fn_nodes': 39,\n",
      "                       'fp_edges': 60,\n",
      "                       'fp_nodes': 0,\n",
      "                       'ns_nodes': 0,\n",
      "                       'ws_edges': 47},\n",
      "        'version': '0.1.2.dev104+gb367f32'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ctc_results = run_metrics(\n",
    "    gt_data=gt_data,\n",
    "    pred_data=pred_data,\n",
    "    matcher=CTCMatcher(),\n",
    "    metrics=[CTCMetrics()],\n",
    ")\n",
    "pp.pprint(ctc_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an IOU matcher which supports a minimum threshold for overlap and run division metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching frames: 100%|██████████| 92/92 [00:00<00:00, 186.84it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The matched data uses a matcher that does not meet the requirements of the metric. Check the documentation for the metric for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m iou_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgt_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgt_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatcher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIOUMatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mDivisionMetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_frame_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m pp\u001b[38;5;241m.\u001b[39mpprint(iou_results)\n",
      "File \u001b[0;32m~/Code/traccuracy/src/traccuracy/_run_metrics.py:43\u001b[0m, in \u001b[0;36mrun_metrics\u001b[0;34m(gt_data, pred_data, matcher, metrics)\u001b[0m\n\u001b[1;32m     41\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[0;32m---> 43\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatched\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result\u001b[38;5;241m.\u001b[39mto_dict())\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/Code/traccuracy/src/traccuracy/metrics/_base.py:60\u001b[0m, in \u001b[0;36mMetric.compute\u001b[0;34m(self, matched, override_matcher)\u001b[0m\n\u001b[1;32m     58\u001b[0m     valid_matcher \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_matcher(matched)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_matcher:\n\u001b[0;32m---> 60\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     61\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe matched data uses a matcher that does not meet the requirements \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the metric. Check the documentation for the metric for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m         )\n\u001b[1;32m     65\u001b[0m res_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute(matched)\n\u001b[1;32m     67\u001b[0m results \u001b[38;5;241m=\u001b[39m Results(\n\u001b[1;32m     68\u001b[0m     results\u001b[38;5;241m=\u001b[39mres_dict,\n\u001b[1;32m     69\u001b[0m     matcher_info\u001b[38;5;241m=\u001b[39mmatched\u001b[38;5;241m.\u001b[39mmatcher_info,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     pred_name\u001b[38;5;241m=\u001b[39mmatched\u001b[38;5;241m.\u001b[39mpred_graph\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     73\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: The matched data uses a matcher that does not meet the requirements of the metric. Check the documentation for the metric for more information."
     ]
    }
   ],
   "source": [
    "iou_results = run_metrics(\n",
    "    gt_data=gt_data,\n",
    "    pred_data=pred_data,\n",
    "    matcher=IOUMatcher(iou_threshold=0.1, one_to_one=True),\n",
    "    metrics=[DivisionMetrics(max_frame_buffer=2)],\n",
    ")\n",
    "pp.pprint(iou_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traccuracy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
